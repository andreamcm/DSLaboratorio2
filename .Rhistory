# Ivette
setwd("C:/Users/DELL/Documents/UVG/VIII_Semestre/Data Science/DSLaboratorio2")
library(class)
library(caret)
# --------------------
datos <- read.csv("train.csv")
datos_relevantes <- datos[, c("LotFrontage", "YearRemodAdd", "YearBuilt", "GarageCars", "PoolArea", "YrSold", "SalePrice")]
# Separación de datos en entrenamiento y prueba
# ----------------------------------------------
set.seed(123)
porciento <- 60/100 #Porciento en el que se partirÃ¡n los datos
muestra<-sample(1:nrow(datos_relevantes),porciento*nrow(datos_relevantes))#Muestra aleatoria de numeros de un vector
trainSet<-datos_relevantes[muestra,] #Obtengo las filas de los elementos que estan en el sector de muestra
testS
datos <- read.csv("train.csv")
datos_relevantes <- datos[, c("LotFrontage", "YearRemodAdd", "YearBuilt", "GarageCars", "PoolArea", "YrSold", "SalePrice")]
# Separación de datos en entrenamiento y prueba
# ----------------------------------------------
set.seed(123)
porciento <- 60/100 #Porciento en el que se partirÃ¡n los datos
muestra<-sample(1:nrow(datos_relevantes),porciento*nrow(datos_relevantes))#Muestra aleatoria de numeros de un vector
trainSet<-datos_relevantes[muestra,] #Obtengo las filas de los elementos que estan en el sector de muestra
testSet<-datos_relevantes[-muestra,]
#Analisis exploratorio con nuevas variables
glimpse(datos_relevantes)
library(ggthemes)
library(dplyr)
library(ggplot2)
library(readxl)
library(gmodels)
library(Hmisc)
library(ggthemes)
library(class)
library(caret)
install.packages(gmodels)
#Analisis exploratorio con nuevas variables
glimpse(datos_relevantes)
CrossTable(datos_relevantes$YearBuilt, datos_relevantes$SalePrice)
library(gmodels)
install.packages(gmodels)
install.packages(gmodels)
install.packages("gmodels")
CrossTable(datos_relevantes$YearBuilt, datos_relevantes$SalePrice)
library(gmodels)
CrossTable(datos_relevantes$YearBuilt, datos_relevantes$SalePrice)
#Analisis exploratorio con nuevas variables
summary(datos_relevantes)
ks.test(datos_relevantes$LotFrontage,rnorm(length(datos_relevantes$LotFrontage)))
hist(datos_relevantes$LotFrontage, col="lightcyan", main="Histograma de LotFrontage")
hist(datos_relevantes$LotFrontage, col="lightcyan", main="Histograma de LotFrontage")
qqnorm(datos_relevantes$LotFrontage, main="LotFrontage")
qqline(datos_relevantes$LotFrontage, col = "red")
ks.test(datos_relevantes$LotFrontage,rnorm(length(datos_relevantes$LotFrontage)))
st(datos_relevantes$YearRemodAdd, col="lightcyan", main="Histograma de YearRemodAdd")
qqnorm(datos_relevantes$YearRemodAdd, main="YearRemodAd
#YearRemoAdd
hist(datos_relevantes$YearRemodAdd, col="lightcyan", main="Histograma de YearRemodAdd")
#YearRemoAdd
hist(datos_relevantes$YearRemodAdd, col="lightcyan", main="Histograma de YearRemodAdd")
qqnorm(datos_relevantes$YearRemodAdd, main="YearRemodAdd")
qqline(datos_relevantes$YearRemodAdd, col = "red")
ks.test(datos_relevantes$YearRemodAdd,rnorm(length(datos_relevantes$YearRemodAdd)))
#YearRemoAdd
hist(datos_relevantes$YearBuilt, col="lightcyan", main="Histograma de YearBuilt")
qqnorm(datos_relevantes$YearBuilt, main="YearBuilt")
qqline(datos_relevantes$YearBuilt, col = "red")
ks.test(datos_relevantes$YearBuilt,rnorm(length(datos_relevantes$YearBuilt)))
#LotArea
hist(datos_relevantes$LotArea, col="lightcyan", main="Histograma de LotArea")
#LotArea
hist(datos_relevantes$LotArea, col="lightcyan", main="Histograma de LotArea")
datos_relevantes <- datos[, c("LotArea", "YearRemodAdd", "YearBuilt", "GarageCars", "PoolArea", "YrSold", "SalePrice")]
#LotArea
hist(datos_relevantes$LotArea, col="lightcyan", main="Histograma de LotArea")
qqnorm(datos_relevantes$LotArea, main="LotArea")
qqline(datos_relevantes$LotArea, col = "red")
ks.test(datos_relevantes$LotArea,rnorm(length(datos_relevantes$LotArea)))
#GarageCars
hist(datos_relevantes$GarageCars, col="lightcyan", main="Histograma de GarageCars")
qqnorm(datos_relevantes$GarageCars, main="GarageCars")
qqline(datos_relevantes$GarageCars, col = "red")
ks.test(datos_relevantes$GarageCars,rnorm(length(datos_relevantes$GarageCars)))
#PoolArea
hist(datos_relevantes$PoolArea, col="lightcyan", main="Histograma de PoolArea")
qqnorm(datos_relevantes$PoolArea, main="PoolArea")
qqline(datos_relevantes$PoolArea, col = "red")
ks.test(datos_relevantes$PoolArea,rnorm(length(datos_relevantes$PoolArea)))
#YrSold
hist(datos_relevantes$YrSold, col="lightcyan", main="Histograma de YrSold")
qqnorm(datos_relevantes$YrSold, main="YrSold")
qqline(datos_relevantes$YrSold, col = "red")
ks.test(datos_relevantes$YrSold,rnorm(length(datos_relevantes$YrSold)))
#SalePrice
hist(datos_relevantes$SalePrice, col="lightcyan", main="Histograma de SalePrice")
qqnorm(datos_relevantes$SalePrice, main="SalePrice")
qqline(datos_relevantes$SalePrice, col = "red")
ks.test(datos_relevantes$SalePrice,rnorm(length(datos_relevantes$SalePrice)))
# ----------------------------------------------
set.seed(123)
porciento <- 60/100 # 60% para training y 40% para pruebas
muestra<-sample(1:nrow(datos_relevantes),porciento*nrow(datos_relevantes))# Seleccion de muestras aleatorias
trainSet<-datos_relevantes[muestra,] # Grupo de entrenamiento
testSet<-datos_relevantes[-muestra,] # Grupo de pruebas
# Regresión lineal
# ----------------
modeloRL <- lm(SalePrice~., data = trainSet)
summary(modeloRL)
prediccionRL <- predict(modeloRL, newdata = testSet)
testSet$rlprediccion <- prediccionRL
prediccionRL
diferencia <- abs(testSet$rlprediccion-testSet$SalePrice)
diferencia
cfmrl <- confusionMatrix(prediccionRL, testSet)
#Generación del modelo
modeloLinealSimple<-lm(mpg~wt, data = trainSet)
summary(modeloLinealSimple)
#predicción
prediccion<-predict(modeloLinealSimple,newdata = testSet[,2:ncol(testSet)])
# Se agrega la predicción al conjunto de entrenamiento
testSet$mpgPred<-prediccion
#Ver la diferencia entre lo real y lo predicho
dif<-abs(testSet$mpgPred-testSet$mpg)
#Hay que establecer la diferencia mínima para saber quienes son los mejores clasificados
testSet$mpgPred <-NULL
#Generación del modelo
modeloLinealSimple<-lm(mpg~wt, data = trainSet)
library(class)
library(caret)
# ----------------
modeloRL <- lm(SalePrice~., data = trainSet)
summary(modeloRL)
prediccionRL <- predict(modeloRL, newdata = testSet)
testSet$rlprediccion <- prediccionRL
prediccionRL
diferencia <- abs(testSet$rlprediccion-testSet$SalePrice)
diferencia
cfmrl <- confusionMatrix(prediccionRL, testSet)
library(corrplot)
# Analisis de correlacion
corrcuant <- cor(datos_relevantes, use="complete.obs", method="pearson")
corrcuant
corrplot(corrcuant, method = "square")
# Ivette
setwd("C:/Users/DELL/Documents/UVG/VIII_Semestre/Data Science/DSLaboratorio2")
library(dplyr)
library(ggplot2)
library(corrplot)
library(gmodels)
library(Hmisc)
library(ggthemes)
library(class)
library(caret)
# --------------------
# Lectura de los datos
# --------------------
datos <- read.csv("train.csv")
datos_relevantes <- datos[, c("LotArea", "YearRemodAdd", "YearBuilt", "GarageCars", "PoolArea", "YrSold", "SalePrice")]
# ----------------------------------------------
# Separación de datos en entrenamiento y prueba
# ----------------------------------------------
set.seed(123)
porciento <- 60/100 # 60% para training y 40% para pruebas
muestra<-sample(1:nrow(datos_relevantes),porciento*nrow(datos_relevantes))# Seleccion de muestras aleatorias
trainSet<-datos_relevantes[muestra,] # Grupo de entrenamiento
testSet<-datos_relevantes[-muestra,] # Grupo de pruebas
NROW(trainSet)
#KNN
#Now creating seperate dataframe for 'Creditability' feature which is our target.
trainSet <- gc.subset[datos_relevantes,1]
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) } # creating a normalize function for easy convertion.
porciento <- 60/100 # 60% para training y 40% para pruebas
muestra<-sample(1:nrow(datos_relevantes),porciento*nrow(datos_relevantes))# Seleccion de muestras aleatorias
trainSet<-datos_relevantes[muestra,] # Grupo de entrenamiento
testSet<-datos_relevantes[-muestra,] # Grupo de pruebas
#Now creating seperate dataframe for 'Creditability' feature which is our target.
trainSet.gc_labels <- trainSet[muestra,1]
testSet.gc_labels  <- testSet[-muestra,1]
knn.26 <-  knn(train=trainSet, test=testSet, cl=trainSet.gc_labels, k=26)
na.omit(datos_relevantes)
# ----------------------------------------------
# Separación de datos en entrenamiento y prueba
# ----------------------------------------------
set.seed(123)
porciento <- 60/100 # 60% para training y 40% para pruebas
muestra<-sample(1:nrow(datos_relevantes),porciento*nrow(datos_relevantes))# Seleccion de muestras aleatorias
trainSet<-datos_relevantes[muestra,] # Grupo de entrenamiento
testSet<-datos_relevantes[-muestra,] # Grupo de pruebas
#Now creating seperate dataframe for 'Creditability' feature which is our target.
trainSet.gc_labels <- trainSet[muestra,1]
testSet.gc_labels  <- testSet[-muestra,1]
NROW(trainSet)
knn.26 <-  knn(train=trainSet, test=testSet, cl=trainSet.gc_labels, k=26)
knn.26 <-  knn(train=trainSet, test=testSet, cl=trainSet.gc_labels, k=29)
knn.26 <-  knn(train=trainSet[, -1], test=testSet[, -1], cl=trainSet.gc_labels, k=29)
#Now creating seperate dataframe for 'Creditability' feature which is our target.
trainSet.gc_labels <- trainSet[muestra,1]
testSet.gc_labels  <- testSet[-muestra,1]
View(trainSet)
View(testSet)
knn.26 <-  knn(train=trainSet[, -1], test=testSet[, -1], cl=trainSet.gc_labels, k=29)
knn.26 <-  knn(train=trainSet, test=testSet, cl=trainSet.gc_labels, k=29)
knn.26 <-  knn(train=trainSet, test=testSet, cl=trainSet.gc_labels, k=29)
#Now creating seperate dataframe for 'Creditability' feature which is our target.
trainknn.26 <-  knn(train=trainSet, test=testSet, cl=trainSet.gc_labels, k=29)Set.gc_labels <- trainSet[muestra,1]
#Now creating seperate dataframe for 'Creditability' feature which is our target.
trainSet.gc_labels <- trainSet[muestra,1]
testSet.gc_labels  <- testSet[-muestra,1]
NROW(trainSet)
knn.26 <-  knn(train=trainSet, test=testSet, cl=trainSet.gc_labels, k=29)
trainSet.gc_labels
NROW(trainSet.gc_labels)
na.omit(trainSet.gc_labels)
NROW(trainSet.gc_labels)
knn.26 <-  knn(train=trainSet, test=testSet, cl=trainSet.gc_labels, k=29)
trainSet.gc_labels
na.omit(trainSet.gc_labels)
trainSet.gc_labels
datos_relevantes <- na.omit(datos_relevantes)
#Analisis exploratorio con nuevas variables
summary(datos_relevantes)
# ----------------------------------------------
# Separación de datos en entrenamiento y prueba
# ----------------------------------------------
set.seed(123)
porciento <- 60/100 # 60% para training y 40% para pruebas
muestra<-sample(1:nrow(datos_relevantes),porciento*nrow(datos_relevantes))# Seleccion de muestras aleatorias
trainSet<-datos_relevantes[muestra,] # Grupo de entrenamiento
testSet<-datos_relevantes[-muestra,] # Grupo de pruebas
#Now creating seperate dataframe for 'Creditability' feature which is our target.
trainSet.gc_labels <- trainSet[muestra,1]
testSet.gc_labels  <- testSet[-muestra,1]
trainSet.gc_labels
trainSet.gc_labels
NROW(trainSet.gc_labels)
knn.26 <-  knn(train=trainSet, test=testSet, cl=trainSet.gc_labels, k=29)
trainSet.gc_labels <- na.omit(trainSet.gc_labels)
trainSet.gc_labels
NROW(trainSet.gc_labels)
knn.26 <-  knn(train=trainSet, test=testSet, cl=trainSet.gc_labels, k=29)
#Now creating seperate dataframe for 'Creditability' feature which is our target.
trainSet.gc_labels <- trainSet[muestra,1]
testSet.gc_labels  <- testSet[-muestra,1]
trainSet.gc_labels <- na.omit(trainSet.gc_labels)
trainSet.gc_labels
#Now creating seperate dataframe for 'Creditability' feature which is our target.
trainSet.gc_labels <- trainSet[muestra,1]
testSet.gc_labels  <- testSet[-muestra,1]
trainSet.gc_labels <- na.omit(trainSet.gc_labels)
trainSet.gc_labels
#Now creating seperate dataframe for 'Creditability' feature which is our target.
trainSet.gc_labels <- trainSet[muestra,1]
testSet.gc_labels  <- testSet[-muestra,1]
trainSet.gc_labels
knn.26 <-  knn(train=trainSet, test=testSet, cl=trainSet.gc_labels, k=29)
